Metadata-Version: 2.4
Name: template-project
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.12
Description-Content-Type: text/markdown
Requires-Dist: pytest==8.3.4
Requires-Dist: pytest-cov==6.0.0
Requires-Dist: black==24.10.0
Requires-Dist: ruff==0.8.4
Requires-Dist: pylint==3.3.2
Requires-Dist: flake8==7.1.1
Requires-Dist: flake8-pyproject>=1.2.3
Requires-Dist: mypy==1.13.0
Requires-Dist: complexipy==1.2.0
Requires-Dist: isort==5.13.2
Requires-Dist: ipykernel>=6.29.5
Requires-Dist: polars>=1.31.0
Requires-Dist: pillow>=11.3.0
Requires-Dist: torch>=2.7.1
Requires-Dist: numpy>=2.3.1
Requires-Dist: matplotlib>=3.10.3
Requires-Dist: tqdm>=4.67.1
Requires-Dist: torchvision>=0.22.1
Requires-Dist: torchmetrics[detection]>=1.7.4
Requires-Dist: pycocotools>=2.0.10
Requires-Dist: faster-coco-eval>=1.6.7

# Project 2

The goal of this lab assignment is to develop the **YOLO** model to solve a object detection task, where we have to detect raccoons in an image.

You will have to complete some functions related with data processing, the architecture of the model and its loss function, the training of the model and some auxiliary utilities.

## Evaluation

This project will be graded in the following way:
- 7.5 points will be graded by **automatic tests**, that can be verified by the criteria of a professor if it is necessary, for example, if the test is fulfilled but the goal of the function/class to be completed is not reached.
- 2 points will come from the **inspection of the code** by a professor. These 2 points are meant to assess things that cannot be measured by automatic testing, such as code style and organization.
- The remaining 0.5 points will come from **tools to ensure code quality**. For example, you will have to pass formatters and linters such as Black, Mypy or Flake8. 
- You will have a **partial view of the tests**, but in the end professors will run all tests created. Therefore, do not just try to pass the tests, but do a good code and make sure everything is correct.


## Structure of the repo

- The only code you have to modified is inside the ``src`` folder. You can see some functions are already given to you, as they do not contribute much to the subject itself.

- The ``tests`` folder contains the tests to check that your code is working correctly.

- The ``data`` folder contains the original images and labels of the dataset.

- The ``images`` folder contains some images with the evolution of the training loss and predictions for the dataset. They are useful to see how training and predictions should be. However, by the end of the project, you should delete them and save your own results.

- The ``weights`` folder is the folder where you will save the weights of the model.


## Parts of the project

### Exercise 1: Dataset (1 point)

In this exercise you will implement the `Dataset` class adapted to our object detection problem.

You have to complete the following functions:

- ``_generate_label``: Obtain the correct label from the txt format as a $S\times S\times (5\cdot B + C)$ tensor. (0.5 points)
- ``__get_item__``: Obtain the image and label associated with the image of index $i$. (0.5 points)

### Exercise 2: Utilities (1 points)

In this exercise you will implement some auxiliary functions needed in the rest of the project.

- ``iou``: Function to calculate the Intersection over Union (IoU) between two bounding boxes. (0.25 points)
- ``nms``: Function to perform Non Max Suppression (NMS). (0.5 points)
- ``to_image_coords``: Function to transform coordinates from relative to the cell to relative to the hole image. (0.25 points)

### Exercise 3: Loss Function (2.5 points)

In this exercise you will implement the loss function that was used in the original paper.

You have to complete the following functions:

- ``_coordinates_loss``: Loss associated with the error of the coordinates of the bounding box. Maybe you can leave it for the end and do the other sections first, as this one is the most difficult. (0.5 points)
- ``_object_loss``: Loss associated with predicting if there is an object in the cell. (0.5 points)
- ``_no_object_loss``: Loss associated with predicting if there is not an object in the cell. (0.5 points)
- ``_class_loss``: Loss associated with the predicted class of the object in case it exists. (0.5 points)
- ``forward``: Forward pass of the hole loss function. (0.5 points)

### Exercise 4: Model Architecture (1 point)

In this exercise you will implement the architecture of the model.

You have to complete the following functions:

- ``_create_cnn``: Creates the CNN of the model. (0.5 points)
- ``_create_mlp``: Creates the MLP of the model. (0.25 points)
- ``forward``: Forward pass of the model. (0.25 points)

### Exercise 5: Training (2 points)

In this exercise you will implement the training of the model. You should achieve at least a mAP of 0.4; otherwise the mark of all exercises in this part will be divided by two.

You have to complete the following functions:

- ``_get_loaders``: Obtains the train and test dataloaders. (0.25 points)
- ``_make_epoch_train``: Trains the model one epoch. (0.75 points)
- ``fit``: Trains the model many epochs. (0.75 points)
- ``test``: Checks how the model performs on the test set. (0.25 points)


## Tips

- At first, to generate the images and labels in the correct format, you should execute in terminal:

        python -m src.data.transform_data

- After training, you can check how it went looking at the evolution of the losses and some predictions. To generate the predictions, you can execute in terminal:

        python -m src.example

    You should see some images like the ones above. Ideally the mAP evolution would have less overfitting. We could use a validation set and early stopping, but this is not the main point of the project. Also, the predicted labels are in red and the true labels in blue.

    <center>

    ![alt text](images/training/evolution_loss_50.png)

    </center>

    <center>

    ![alt text](images/training/evolution_map.png)

    </center>

    <center>

    ![alt text](images/predictions/test/raccoon-7.jpg)

    </center>

    <center>

    ![alt text](images/predictions/train/raccoon-9.jpg)

    </center>

- If the results are not great, you change some parameters in ```constants.py```, like `S`, `ARCHITECTURE`, `TARGET_SIZE_IMG`, `LAMBDA_COORD` , `LAMBDA_NOOBJ`, `MODEL`, `LR`, `BATCH_SIZE` or `EPOCHS`, or the MLP used in the architecture.

- In the loss function, you can assume that always $B=2$ and "hardcode" some parts for that value, but try not to abuse it.

- In the loss associated to the coordinates of the bounding box, the square root is used for height and width, so remember to use the absolute value there, because at first predictions will be random, so negative numbers can appear. However, by doing this, we see a prediction of $-x$ as if it was the same as $x$, but we want to penalize predicting negative numbers. You can use the ``torch.sign`` function to deal with this.

## Others (0.5 points)

To run these checks, the following commands must be executed:

    mypy src
    black --check .
    flake8 --max-line-length 88 src
